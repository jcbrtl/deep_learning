{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Stats\n",
    "> Exploratory Data Analysis in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-1 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**:- Do first babies come out early?\n",
    "\n",
    "**Anecdotal evidence**:- This is the evidence based on unpublished data and usually personal. Like we can give examples of our friends. But there are flaws in this evidence, namely \n",
    "    \n",
    "* Small number of observations \n",
    "* selection bias (as people you join in this conversation would be those whose first baby was late)\n",
    "* Confirmation bias (people who believe the claim are more likely to come up with examples that confirm it, and vice versa for those who do not believe it)\n",
    "    \n",
    "To solve this problem using **statistics**, we will do:\n",
    "\n",
    "1. Data collection\n",
    "2. Descriptive statistics: generate statistics that summarize the data concisely\n",
    "3. Exploratory data analysis: look for patterns, differences,\n",
    "4. Estimation: use data from sample population to estimate characteristics of the general population\n",
    "5. Hypothesis testing: When we see difference between groups, we will evaluate whether the effect might have happened by chance.\n",
    "\n",
    "Important terms:\n",
    "* cross-sectional study: study that collects data about a population at a particular point in time\n",
    "* cycle: in repeated cross-sectional study, each repetition is called a cycle\n",
    "* longitudinal study: study that follows a population over time, collecting from the same group repeatedly\n",
    "* population: group we are interested in studying\n",
    "* sample: subset of population used to collect data\n",
    "* representative: a sample is representative if every member of the population has the same chance of being in the sample\n",
    "* oversampling: the technique of increasing the representation of a sub-population in order to avoid errors due to small sample size.\n",
    "* recode: a value that is generated by calculation and other logic applied to raw data.\n",
    "\n",
    "Create some validation statistics. Like compute the counts, means or something and store these values. When you move your data from one place to another or someone else tries to do something with your work, then can compare the validation statistics to see the data they are working with is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-2 Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms are the best way to describe a variable. Using histogram you can easily identify **outliers**. After identifying the outliers, see if they are due to some errors or are some rare cases.\n",
    "\n",
    "These are some of the statistics that we want to report\n",
    "* central tendency(mean): do the values tend to cluster around a particular point\n",
    "* modes: is there more than one mode\n",
    "* spread(variance): how much variability is there in the values\n",
    "* tails: how quickly the population drops off as we move away from the modes\n",
    "* outliers: are there extreme values and are they natural or not\n",
    "\n",
    "These are called **summary statistics**. \n",
    "\n",
    "- mean: we use the normal formula\n",
    "- average: can be used to refer to any measure of central tendency\n",
    "\n",
    "To measure the effect size take the **difference of the means**.\n",
    "\n",
    "Cohen's d statistic is, can also be used to measure the effect size in terms of variability among groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CohenEffectSize(group1, group2):\n",
    "    diff = group1.mean() - group2.mean()\n",
    "    var1, var2 = group1.var(), group2.var()\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    pooled_var = (n1*var1 + n2*var2) / (n1+n2)\n",
    "    d = diff/math.sqrt(pooled_var)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above program would be the difference in means is 0.028 standard deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-3 Probability Mass Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to represent a distribution is PMF, which maps each value to a probability. To get PMF, compute the histogram and then divide by total n (i.e. normalize).\n",
    "\n",
    "To plot PMF\n",
    "* bar graph: if the number of values is small\n",
    "* step function: the the number of values is large and the PMF is smooth (just bar plot but only the outline is drawn, it is not the cumulative one)\n",
    "\n",
    "Histograms and PMFs are useful wile you are exploring data and trying to identify patterns and relationships. Once you have got the idea, the next step is to design a visualization that makes the patterns you have identified as clear as possible.\n",
    "\n",
    "**Biased PMFs**\n",
    "\n",
    "If you want to know the average number of students in each class, you can do it in two ways\n",
    "* ask the college, and they would use the records to tell you the actual average value\n",
    "* if you ask the students, you are probably going to get a large value because there is more chance that you will get students from large class size and they will all say the large class size number.\n",
    "\n",
    "In this way we can see how we might end with biased PMFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-4 Cumulative Distribution Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMFs work well if the number of values is small. But as the number of values increase the probability of each value decreases and effect of random noise increases. This can be mitigated by binning the data. If the size of the bins is large then we will smooth out noise, but it might also smooth out useful information.\n",
    "\n",
    "An **alternative that avoid this is cumulative distribution function (CDF)**\n",
    "\n",
    "The tests report score as **percentile rank**. It is the fraction of the people who scored lower than you (or the same). So are in the 90th percentile, it means you are better than 90% of the people who took the exam.\n",
    "\n",
    "**Percentile**, is the reverse of above. So a percentile goes from 90th percentile to the actual score that you scored.\n",
    "\n",
    "**CDFs** is a function that maps from a value to its percentile rank. Say you plot a graph with weeks on x-axis and CDF on y-axis. Then to interpret this graph, you can say that 10% of value on y-axis are shorter than 36 weeks on the x-axis. **CDFs are very useful for comparing distribution**.\n",
    "\n",
    "**Interquartile range** is the measure of the spread of a distribution (difference between 75th and 25th percentiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-5 Modeling distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution we discussed so far are called **empirical distributions** because they used finite samples. The alternative is **analytic distribution**, which is a mathematical function.\n",
    "\n",
    "### Exponential Distribution\n",
    "\\begin{equation*}\n",
    "CDF(x) = 1 - e^{-\\lambda x}\n",
    "\\end{equation*}\n",
    "\n",
    "This distribution comes up when we look at a series of events and measure the times between events. If the events are equally likely to occur we get an exponential distribution. The mean of this distribution is $1/\\lambda$, so you can use this to get the $\\lambda$ value of your distribution. The mean is susceptible to outliers, so you can use median in that case, $ln(2)/median$.\n",
    "\n",
    "### Normal Distribution\n",
    "The CDF is like a 'S' value graph.\n",
    "\n",
    "### Lognormal Distribution\n",
    "If the $log(x)$ is a normal distribution, then it is forms lognormal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of a CDF is called a **PDF**. The result at a particular value is not useful, as it gives probability density, not probability.\n",
    "\n",
    "**Skewness** is a property that describes the shape of a distribution. If the distribution is symmetric around its central tendency, it is unskewed . If the values extend farther to the right, it is \"right skewed\" and if the values extend left, it is \"left skewed\".\n",
    "\n",
    "You can look at the mean and median for skewness. Also, **Pearson's median skewness coefficient** can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PearsonMedianSkewness(x):\n",
    "    median = x.median()\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    return 3*(mean-median)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statistic is robust meaning it is less vulnerable to the effect of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-7 Relationships Between Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter plots** are good.\n",
    "\n",
    "**Correlation** is intended to quantify the strength of the relationship between two variables. The problem is the variables may not be in the same units, or come from different distributions. Use these techniques\n",
    "* **Pearson product-moment correlation coefficient**: Transform each value to standard deviation from the mean.\n",
    "* **Spearman rank correlation coefficient**: Transform each value to Percentile rank.\n",
    "\n",
    "**Covariance** is a tendency of the variables to vary together. Take product of the difference of the means and divide by n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-8 Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large sample variance is a good estimator, but for small samples it tends to be too low. For this reason variance produces a **biased** estimator. For this reason we divide by $N-1$ in the variance formula, which produces unbiased estimate.\n",
    "\n",
    "Variation in the estimate caused by random selection is called **sampling error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch-9 Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental question we want to address is whether the effects we see in a sample are likely to appear in the larger population i.e. the effects we saw are due to the sample given to us or not.\n",
    "\n",
    "**Classical hypothesis testing**: Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?\n",
    "1. Choose the thing that you want to measure. Like difference in means between two groups.\n",
    "2. Define a **null hypothesis**, which is based on the assumption that the apparent effect is not real.\n",
    "3. Compute a **p-value**, which is the probability of seeing the apparent effect if the null hypothesis is true.\n",
    "4. If the value is small, it means that it is unlikely to have occurred by chance. So in that case it is more likely to appear in the large population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "25",
    "lenVar": "50"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
